---
layout: 'post'
title: 'aiacademy: 自然語言處理 NLP'
permalink: 'aiacademy/week11/nlp-basice'
tags: aiacademy nlp text-mining
---

- [陳縕儂](https://www.csie.ntu.edu.tw/~yvchen/){:target="_back"}

## NLP Basics - Meaning Representation

<iframe src="https://www.youtube.com/embed/_fsfsd_bRzg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

- Meaning Representations

   - Defintion of "Meaning"

      - the idea that is represented by a word, phrase, etc.
      - the idea that a person wants to express by using words, signs, etc.
      - the idea that is expressed in a word of writing, art, etc

- Meaning Representations in Computers

   - Knowledge-Based Representation
      - 有一本辭典，一位老師，去查特徵
   - Corpus-Based Representation
      - 靠 big data 去認字，從前後文去猜 `"某字"` 
      
### Knowledge-Based Representation

   - Hypernyms (is-a) relationships of [WordNet](https://wordnet.princeton.edu/){:target="_back"}

   ![Imgur](https://i.imgur.com/Ik3HqkI.gif)


## NLP Basics - Corpus Based Representation

<iframe src="https://www.youtube.com/embed/L4iGmNdrwf8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Meaning Representations in Compters

- Corpus-Based Representation

   ![Imgur](https://i.imgur.com/y2uDINX.gif)

   ![Imgur](https://i.imgur.com/d2jiSOw.gif)

- Windoe-Based Co-occurrence Matrix

   - sparsity (資料內很多０)

   ![Imgur](https://i.imgur.com/FUsd3qG.gif)

- Low-Dimensional Dense Word Vector

   ![Imgur](https://i.imgur.com/cKSzGOx.gif)

   ![Imgur](https://i.imgur.com/4FzLuyL.gif)

   ![Imgur](https://i.imgur.com/3uqydow.gif)

- Summary

   - Knowledge-based representation
   - Corpus-based representation
      - Atomic symbol
      - Neighbors
         - High-dimensional sparse word vector
         - Low-dimensional dense word vector
            - Method 1 - dimension reduction
            - Method 2 - direct learning


## text mining 文字探勘

<iframe src="https://www.youtube.com/embed/LjOJ6M3Bgno" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

- 甚麼是文字探勘?

   - 從文本產生有價值的訊息
      - 從非結構化到結構化
      - 分析結構化並得到有價值的訊息

- 文字探勘應用

   - 垃圾郵件檢測
   - 情感分析
   - 命名實體辨識
   - 文本摘要

![Imgur](https://i.imgur.com/xTMGNto.gif)

![Imgur](https://i.imgur.com/4Us36Hd.gif)

__中文分詞__

- 與英文文字類似，差別在於需要做斷詞處理

- [jieba](https://github.com/fxsjy/jieba){:target="_back"}


## text mining preprocess

<iframe width="560" height="315" src="https://www.youtube.com/embed/bYoD9X29gMI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

- PTT 資料及爬蟲

   - @afunTW

      - [https://github.com/afunTW/ptt-web-crawler](https://github.com/afunTW/ptt-web-crawler){:target="_bakc"}

__文章斷詞__

- [jieba](https://github.com/fxsjy/jieba){:target="_back"}

   - 號稱最好的 Python 中文斷詞套件
   - 支持四種斷詞引擎
      - 最大概率法、隱式法爾科夫模型、混合模型、索引模型
   - 可以標註詞性

- [中研院斷詞系統](http://ckipsvr.iis.sinica.edu.tw/){:target="_back"}

   - 號稱地表最強中文斷詞系統(96% 精準度)
   - 自動標註詞性
   - 需要申請...
   
__jieba 斷詞__

- 設定　字典辭庫　與　stopwords 辭庫

   - stop_words
      - EX: `了、阿、吧、我們...`
      - 很常出現的字，但沒特別意義
   - set_dictionary
      - 把繁體中文字典加入
   
~~~python
## set dictionary (can define yourself)
jieba.set_dictionary('jieba/dict.txt.big')
stop_words = open('jieba/stop_words.txt', encoding='utf8').read().splitlines()
~~~

~~~python
data = pd.read_csv('data/article_preprocessed.csv')
data = data['content'].tolist()

sentences = []

for i, text in enumerate(tqdm_notebook(data)):
    line = []

    for w in jieba.cut(text, cut_all=False):
        
        ## remove stopwords and digits
        ## can define your own rules
        if w not in stop_words and not bool(re.match('[0-9]+', w)):
            line.append(w)

    sentences.append(line)

print(sentences[0:5])
~~~

~~~
[['韓瑜', '協志', '前妻', '正', '女演員', '周子', '瑜', 'TWICE', '團裡裡面', '台灣', '人', '正', '兩個', '要當', '鄉民', '老婆', '選', '五樓', '真', '勇氣'], ['dear', 'all', '逢甲', '碟仙', '發生', '民國', '七十五年', '三月中', '事情', '一堆', '大學生', '玩', '碟仙', '後發', 'bbs', '成功', '預測', '地震', '小弟', '預言', '都還沒', '出生', '後面', '說', '預言', '一百', '一十六年', '兩岸', '統一', '統一', '對岸', '對岸', '統一', '應該', '不用', '猜', '真的', '存在', '預言', '這種', '事情', '倒底', '被統', '知道', '資料庫', '發文', '日期', '輕鬆', '改變', '拍照', '狀況', '下', '碟仙', '真的假', '有沒有', '科學', '經驗', '法則', '破解', '謠言', '真實', '八卦'], ['晚上', '好', '預備', '唱', '風雲', '山河', '動', '國軍', '早上', '唱', '有沒有', '相關', '八卦', 'Sent', 'from', 'JPTT', 'on', 'my', 'Xiaomi', 'Redmi', 'Note'], ['明天', '早起', '睡覺', '旁邊', 'Youtube', '眼睛', '壞掉', '有沒有', '方法', '早點', '睡', '掛', 'Sent', 'from', 'JPTT', 'on', 'my', 'HTC', 'D10i'], ['一段時間', '注意', 'LOL', '發現', '各大', 'LOL', '討論區', '人數', '明顯', '下降', '趨勢', '實在', '令人', '驚訝', '曾經', '一時', '遊戲', '霸主', '漸漸', '過氣', 'LOL', '確實', '撐', '久', '現在', '算', '厲害', '遊戲', '玩久', '會膩']]
~~~

__posseg (詞性)__

~~~python
from jieba import posseg as pseg
for w, j in pseg.cut(data[0]):
    print(w, ' ', j)
~~~

~~~
韓瑜   nr
是   v
協志   n
的   uj
前妻   n
    x
也   d
是   v
很正   a
的   uj
女演員   x
    x
周子瑜   nr
是   v
TWICE   eng
團裡   q
裡面   f
的   uj
台灣   ns
人   n
    x
也   d
是   v
很正   d
    x
這   zg
兩個   x
要   v
當   p
鄉民   x
的   uj
老婆   n
，   x
你   r
要   v
怎麼   x
選   v
呢   y
?   x
?   x
    x
五   m
樓   n
你   r
真   d
有   v
勇氣   x
~~~
---
layout: "single"
title: 'aiacademy: 深度學習 CNN 考試！'
permalink: 'aiacademy/week7/deep-learning-cnn-quiz'
tags: aiacademy cnn
---

> 考試爆了　ＸＤＤ　

> 檢討開始

1. CNN (Convolutional neural network) 的敘述何者 `"錯誤"?`

   - 不會有gradient vanishing的問題
   - 疊越多層accuracy一定越高
   - 越多層的CNN模型weight數量一定比少層的多

   - __CNN: 可以用來解決 [時間序列的問題](https://machinelearningmastery.com/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting/){:target="_back"}__ ---> 是正確的兒！！！(CNN 可以平行運算，某個程度會比RNN快)



2. 使用物件偵測模型訓練後，測試時發現沒有顯示任何的bound box，以下哪個選項是 `“正確”` 的？

   - 訓練樣本太少，模型沒有學習到
   - 顯示bound box 的threshold定太高了，在模型成效不佳時，無法顯示bound box
   - 在retrain model沒有正確的設定類別
   - [anchor](https://www.d2l.ai/chapter_computer-vision/anchor.html){:target="_back"} 的超參數設定不適合這次的資料集

3. 以下選項哪些對解決overfitting“沒什麼幫助”
   
   - padding: 補零
   - batch normalization: 可讓收斂比較穩定

   __max pooling:__ [參考連結](https://datascience.stackexchange.com/questions/14122/why-convolute-if-max-pooling-is-just-going-to-downsample-the-image-anyway){:target="_back"}
   
      - The intuition is that once a feature has been found, its exact location isn't as important as its rough location relative to other features. The function of the pooling layer is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network, and hence to also control overfitting. It is common to periodically insert a pooling layer in-between successive conv layers in a CNN architecture. The pooling operation provides a form of translation invariance.

4. 經過 3 層　filter size 為　3*3 的　Convolution layers(無padding, strides=1)從而輸出一張 feature map，其中 feature map 的每個 pixel 所得的原圖視野，其大小可約略等價於哪一個單層捲積層產生的視野?

   - 7 x 7


5. `車輛偵測` Data Augmentation 哪個不優
　　
   - 圖片上下翻轉

6. 關於 CNN 提高 accuracy 的方式，以下何者"不太有效"?

   - Convolutional layer 的 kernel size 一直往上調

7. CNN 實現　cifar10 Datasets 哪個參數不太可能出現？

   - max pooling size: 32 x 32

8. hidden layer 輸出透過　Convolution layer 降維，原本上一層的 hidden layer 輸出的格式為　28 x 28 且有 32 張 feature map，以下降維的運作條件何者正確？

   - filter size 1 x 1 x 32 (size 要和上一層的厚度一樣！！！)，且 filter 的數量小於上層，並且不需要padding
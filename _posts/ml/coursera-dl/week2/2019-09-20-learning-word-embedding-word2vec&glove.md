---
layout: "single"
title: 'NLP & Word Embeddings: Word2vec & GloVe'
permalink: 'dl-coursera-sequence-models/week2/nlp-and-word-embeddings-word2vec-glove'
tags: coursera-deep-learning nlp word-embeddings Word2Vec
---

### [NLP and Word Embeddings: Learning word embeddings](https://www.coursera.org/learn/nlp-sequence-models/lecture/APM5s/learning-word-embeddings){:target="_back"}

> 大神說 word embeddings 發展過程中，從很複雜的 algorithm 一直到用超級簡單的　algorithm 跑出來的結果依樣很棒棒。

> __BUT__ 那樣對學習太抽象了，複雜的 algorithm 反而比較好理解～

>  所以大神說古，從難講到現今簡單的　algorithm~

![Imgur](https://i.imgur.com/X3vxWmi.jpg)

![Imgur](https://i.imgur.com/8lzcPxm.jpg)


### [NLP and Word Embeddings: Word2Vec](https://www.coursera.org/learn/nlp-sequence-models/lecture/8CZiw/word2vec){:target="_back"}

- Skip-grams 

   - [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781){:target+""_back}

   - 隨機找 target 

   ![Imgur](https://i.imgur.com/iusH7rI.gif)

   ![Imgur](https://i.imgur.com/tp5Ldqe.gif)

   ![Imgur](https://i.imgur.com/i8TiFrH.gif)

### [NLP and Word Embeddings: Negative sampling](https://www.coursera.org/learn/nlp-sequence-models/lecture/Iwx0e/negative-sampling){:target="_back"}

![Imgur](https://i.imgur.com/w4Y7pFP.gif)

![Imgur](https://i.imgur.com/j54eNxD.gif)

![Imgur](https://i.imgur.com/Rg5jCzF.gif)

### [NLP and Word Embeddings: Glove Word vectors](https://www.coursera.org/learn/nlp-sequence-models/lecture/IxDTG/glove-word-vectors){:target="_back"}


![Imgur](https://i.imgur.com/lFVSE2W.gif)

![Imgur](https://i.imgur.com/tTuRcuZ.gif)

![Imgur](https://i.imgur.com/I3xgzye.gif)







---
layout: "single"
title: 'Gradient Descent with Large Datasets'
permalink: 'ml-coursera/week10/gradient-descent-with-large-datasets'
tags: coursera-machine-learning
---

> 倒數第二週！！　ＧＯＧＯ～～

### [Large scale machine learning - Learning with large datasts](https://www.coursera.org/learn/machine-learning/lecture/CipHf/learning-with-large-datasets){:target="_back"}

> It's not who has the best algorithm that wins. It's who has the most data.


![Imgur](https://i.imgur.com/7BHIAlk.jpg)

![Imgur](https://i.imgur.com/WA0KHfL.jpg)

![Imgur](https://i.imgur.com/DMvWcoD.jpg)



### [Large scale machine learning - Stochastic gradient descent](https://www.coursera.org/learn/machine-learning/lecture/DoRHJ/stochastic-gradient-descent){:target="_back"}

![Imgur](https://i.imgur.com/8Mikhha.jpg)

![Imgur](https://i.imgur.com/H0nanBK.jpg)

#### Stochastic gradient descent

![Imgur](https://i.imgur.com/xfRDc87.jpg)

__畢卡索手稿__

![Imgur](https://i.imgur.com/zylvQ7c.jpg)

__quiz__

![Imgur](https://i.imgur.com/SrhYjYw.jpg)


### [Large scale machine learning - Mini-batch gradient descent](https://www.coursera.org/learn/machine-learning/lecture/9zJUs/mini-batch-gradient-descent){:target="_back"}


#### Mini-batch gredient descent

- Batch gradient descent: Use all m examples in each iteration

- Stocahastic gradient descent: Use 1 example in each iteration

- Mini-batch gradient descent: Use b examples in each iteration

![Imgur](https://i.imgur.com/TPOrRPF.jpg)

#### quiz

![Imgur](https://i.imgur.com/lTT6QJl.jpg)


### [Large scale machine learning - Stochastic gradient descent convergence](https://www.coursera.org/learn/machine-learning/lecture/fKi0M/stochastic-gradient-descent-convergence){:target="_back"}


#### Checking for convergence

![Imgur](https://i.imgur.com/MfTlDYr.jpg)

![Imgur](https://i.imgur.com/3s6jeBZ.jpg)

![Imgur](https://i.imgur.com/8Z7n8W6.jpg)

![Imgur](https://i.imgur.com/W93XTp1.jpg)



